{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the crime thing Dr. Page asked us to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import shutup; shutup.please()\n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.io import arff\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>pop</th>\n",
       "      <th>perHoush</th>\n",
       "      <th>pctBlack</th>\n",
       "      <th>pctWhite</th>\n",
       "      <th>pctAsian</th>\n",
       "      <th>pctHisp</th>\n",
       "      <th>pct12-21</th>\n",
       "      <th>pct12-29</th>\n",
       "      <th>pct16-24</th>\n",
       "      <th>...</th>\n",
       "      <th>burglaries</th>\n",
       "      <th>burglPerPop</th>\n",
       "      <th>larcenies</th>\n",
       "      <th>larcPerPop</th>\n",
       "      <th>autoTheft</th>\n",
       "      <th>autoTheftPerPop</th>\n",
       "      <th>arsons</th>\n",
       "      <th>arsonsPerPop</th>\n",
       "      <th>violentPerPop</th>\n",
       "      <th>nonViolPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NJ</td>\n",
       "      <td>11980.0</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.37</td>\n",
       "      <td>91.78</td>\n",
       "      <td>6.50</td>\n",
       "      <td>1.88</td>\n",
       "      <td>12.47</td>\n",
       "      <td>21.44</td>\n",
       "      <td>10.93</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>114.85</td>\n",
       "      <td>138.0</td>\n",
       "      <td>1132.08</td>\n",
       "      <td>16.0</td>\n",
       "      <td>131.26</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.41</td>\n",
       "      <td>41.02</td>\n",
       "      <td>1394.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PA</td>\n",
       "      <td>23123.0</td>\n",
       "      <td>2.82</td>\n",
       "      <td>0.80</td>\n",
       "      <td>95.57</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0.85</td>\n",
       "      <td>11.01</td>\n",
       "      <td>21.30</td>\n",
       "      <td>10.48</td>\n",
       "      <td>...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>242.37</td>\n",
       "      <td>376.0</td>\n",
       "      <td>1598.78</td>\n",
       "      <td>26.0</td>\n",
       "      <td>110.55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.25</td>\n",
       "      <td>127.56</td>\n",
       "      <td>1955.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OR</td>\n",
       "      <td>29344.0</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.74</td>\n",
       "      <td>94.33</td>\n",
       "      <td>3.43</td>\n",
       "      <td>2.35</td>\n",
       "      <td>11.36</td>\n",
       "      <td>25.88</td>\n",
       "      <td>11.01</td>\n",
       "      <td>...</td>\n",
       "      <td>274.0</td>\n",
       "      <td>758.14</td>\n",
       "      <td>1797.0</td>\n",
       "      <td>4972.19</td>\n",
       "      <td>136.0</td>\n",
       "      <td>376.30</td>\n",
       "      <td>22.0</td>\n",
       "      <td>60.87</td>\n",
       "      <td>218.59</td>\n",
       "      <td>6167.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NY</td>\n",
       "      <td>16656.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.70</td>\n",
       "      <td>97.35</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.70</td>\n",
       "      <td>12.55</td>\n",
       "      <td>25.20</td>\n",
       "      <td>12.19</td>\n",
       "      <td>...</td>\n",
       "      <td>225.0</td>\n",
       "      <td>1301.78</td>\n",
       "      <td>716.0</td>\n",
       "      <td>4142.56</td>\n",
       "      <td>47.0</td>\n",
       "      <td>271.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>306.64</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MN</td>\n",
       "      <td>11245.0</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.53</td>\n",
       "      <td>89.16</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.52</td>\n",
       "      <td>24.46</td>\n",
       "      <td>40.53</td>\n",
       "      <td>28.69</td>\n",
       "      <td>...</td>\n",
       "      <td>91.0</td>\n",
       "      <td>728.93</td>\n",
       "      <td>1060.0</td>\n",
       "      <td>8490.87</td>\n",
       "      <td>91.0</td>\n",
       "      <td>728.93</td>\n",
       "      <td>5.0</td>\n",
       "      <td>40.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9988.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 143 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  State      pop  perHoush  pctBlack  pctWhite  pctAsian  pctHisp  pct12-21  \\\n",
       "0    NJ  11980.0      3.10      1.37     91.78      6.50     1.88     12.47   \n",
       "1    PA  23123.0      2.82      0.80     95.57      3.44     0.85     11.01   \n",
       "2    OR  29344.0      2.43      0.74     94.33      3.43     2.35     11.36   \n",
       "3    NY  16656.0      2.40      1.70     97.35      0.50     0.70     12.55   \n",
       "4    MN  11245.0      2.76      0.53     89.16      1.17     0.52     24.46   \n",
       "\n",
       "   pct12-29  pct16-24  ...  burglaries  burglPerPop  larcenies  larcPerPop  \\\n",
       "0     21.44     10.93  ...        14.0       114.85      138.0     1132.08   \n",
       "1     21.30     10.48  ...        57.0       242.37      376.0     1598.78   \n",
       "2     25.88     11.01  ...       274.0       758.14     1797.0     4972.19   \n",
       "3     25.20     12.19  ...       225.0      1301.78      716.0     4142.56   \n",
       "4     40.53     28.69  ...        91.0       728.93     1060.0     8490.87   \n",
       "\n",
       "   autoTheft  autoTheftPerPop  arsons  arsonsPerPop  violentPerPop  \\\n",
       "0       16.0           131.26     2.0         16.41          41.02   \n",
       "1       26.0           110.55     1.0          4.25         127.56   \n",
       "2      136.0           376.30    22.0         60.87         218.59   \n",
       "3       47.0           271.93     NaN           NaN         306.64   \n",
       "4       91.0           728.93     5.0         40.05            NaN   \n",
       "\n",
       "   nonViolPerPop  \n",
       "0        1394.59  \n",
       "1        1955.95  \n",
       "2        6167.51  \n",
       "3            NaN  \n",
       "4        9988.79  \n",
       "\n",
       "[5 rows x 143 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data\n",
    "\n",
    "df = pd.read_csv('data/CommViolPredUnnormalizedData.txt', encoding='latin-1',header=None)\n",
    "df.columns\n",
    "#the column names are the second word in each row of data/crime_headings.txt\n",
    "with open('data/crime_headings.txt') as f:\n",
    "    headings = f.readlines()\n",
    "col_names = []\n",
    "types = []\n",
    "for heading in headings:\n",
    "    if len(heading.split()) <= 1:\n",
    "        continue\n",
    "    col_names.append(heading.split()[1])\n",
    "    if heading.split()[2] == 'numeric':\n",
    "        types.append(float)\n",
    "    else:\n",
    "        types.append(str)\n",
    "\n",
    "df.columns = col_names\n",
    "\n",
    "#drop drop rows with \"?\" values\n",
    "df = df.replace('?', np.nan)\n",
    "\n",
    "df = df.astype(dict(zip(col_names, types)))\n",
    "\n",
    "#communityname, countyCode, communityCode, fold are not predictive so drop them\n",
    "df = df.drop(['communityname', 'countyCode', 'communityCode', 'fold'], axis=1)\n",
    "df.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#useful functions\n",
    "def drop_rows_missing_target(df):\n",
    "    return df.dropna(subset=['nonViolPerPop'])\n",
    "\n",
    "\n",
    "def fill_with_mean(df):\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == float:\n",
    "            df[column] = df[column].fillna(df[column].mean())\n",
    "    return df\n",
    "\n",
    "def fill_with_median(df):\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == float:\n",
    "            df[column] = df[column].fillna(df[column].median())\n",
    "    return df\n",
    "\n",
    "def convert_categorical_to_numeric(df):\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype != float:\n",
    "            df[column] = df[column].astype('category')\n",
    "            df[column] = df[column].cat.codes\n",
    "    return df\n",
    "\n",
    "def normalize(df):\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == float:\n",
    "            df[column] = (df[column] - df[column].mean()) / df[column].std()\n",
    "    return df\n",
    "\n",
    "def remove_random_features(df, n):\n",
    "    dropped_cols = np.random.choice(df.columns[:-1], n, replace=False)\n",
    "    return df.drop(dropped_cols, axis=1), dropped_cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pseudo-Explainable Approach - Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using targets as features (normalize):\n",
      "Mean Absolute Error: 0.07604501269206164\n",
      "Kept columns: ['larcPerPop', 'burglPerPop', 'autoTheftPerPop', 'robbbPerPop', 'pctWhite', 'nonViolPerPop']\n",
      "\n",
      "\n",
      "\n",
      "Not using targets as features (normalize):\n",
      "Mean Absolute Error: 0.4488394962321919\n",
      "Kept columns: ['pctKids2Par', 'pct2Par', 'pctAllDivorc', 'rentLowQ', 'pct12-17w2Par', 'houseVacant', 'pctHousOccup', 'persHomeless', 'pctMaleDivorc', 'pctFemDivorc', 'pctPopDenseHous', 'kidsBornNevrMarr', 'persPerRenterOccup', 'persPoverty', 'pctWhite', 'State', 'pctWorkMom-6', 'landArea', 'pctSmallHousUnits', 'pctSameState-5', 'rentQrange', 'pctEmployProfServ', 'blackPerCap', 'pctAsian', 'pctBlack', 'pctWfarm', 'pctVacant6up', 'pctKids-4w2Par', 'popDensity', 'ownHousLowQ', 'pctHousWOplumb', 'pctHousWOphone', 'pctEmployMfg', 'pctRetire', 'otherPerCap', 'medOwnCostpct', 'medYrHousBuilt', 'pctVacantBoarded', 'hispPerCap', 'pctSameCounty-5', 'NAperCap', 'pctSameHouse-5', 'pctPoverty', 'medOwnCostPctWO', 'pctBornStateResid', 'pctKidsBornNevrMarr', 'ownHousQrange', 'asianPerCap', 'pctOccupMgmt', 'pctEmploy', 'medGrossRent', 'pctOccupManu', 'persPerOwnOccup', 'pctNotSpeakEng', 'pctWdiv', 'whitePerCap', 'pctUsePubTrans', 'pct12-21', 'pct16-24', 'pctUnemploy', 'pctMaleNevMar', 'pctHisp', 'pctPubAsst', 'medRentpctHousInc', 'pop', 'numForeignBorn', 'pctFgnImmig-10', 'perHoush', 'pctPersOwnOccup', 'pctLowEdu', 'pct12-29', 'pctWorkMom-18', 'medIncome', 'medFamIncome', 'pctCollGrad', 'persEmergShelt', 'pctSpeakOnlyEng', 'pctHousOwnerOccup', 'pctWsocsec', 'pctFgnImmig-8', 'pctForeignBorn', 'pctFgnImmig-3', 'ownHousUperQ', 'pctNotHSgrad', 'pctLargHous', 'persPerOccupHous', 'ownHousMed', 'persPerFam', 'pct65up', 'pctFgnImmig-5', 'pctWwage', 'pctLargHousFam', 'persUrban', 'rentMed', 'pctImmig-10', 'racialMatch', 'perCapInc', 'pctImmig-5', 'pctImmig-8', 'pctPolicHisp', 'pctImmig-3', 'rentUpperQ', 'nonViolPerPop']\n",
      "\n",
      "\n",
      "\n",
      "Using targets as features (no normalize):\n",
      "Mean Absolute Error: 322.81723113207534\n",
      "Kept columns: ['larcPerPop', 'burglPerPop', 'autoTheftPerPop', 'robbbPerPop', 'pctUsePubTrans', 'rapesPerPop', 'pctPersOwnOccup', 'nonViolPerPop']\n",
      "\n",
      "\n",
      "\n",
      "Not using targets as features (no normalize):\n",
      "Mean Absolute Error: 1228.8010275943395\n",
      "Kept columns: ['pctKids2Par', 'pct2Par', 'pctAllDivorc', 'rentLowQ', 'pct12-17w2Par', 'pctFemDivorc', 'persHomeless', 'pctMaleDivorc', 'houseVacant', 'pctHousOccup', 'pctPopDenseHous', 'kidsBornNevrMarr', 'persPerRenterOccup', 'persPoverty', 'pctWorkMom-6', 'pctEmployProfServ', 'State', 'rentQrange', 'landArea', 'pctWhite', 'pctBlack', 'pctSameState-5', 'pctAsian', 'pctSmallHousUnits', 'pctWfarm', 'blackPerCap', 'popDensity', 'pctRetire', 'pctKids-4w2Par', 'otherPerCap', 'pctEmployMfg', 'pctSameCounty-5', 'pct16-24', 'hispPerCap', 'pctHousWOphone', 'ownHousLowQ', 'pctSameHouse-5', 'whitePerCap', 'medOwnCostPctWO', 'pctHisp', 'pctVacant6up', 'pop', 'persPerOwnOccup', 'asianPerCap', 'pctHousWOplumb', 'NAperCap', 'medOwnCostpct', 'pctBornStateResid', 'pctVacantBoarded', 'medYrHousBuilt', 'ownHousQrange', 'pctPoverty', 'pctEmploy', 'pctOccupMgmt', 'pctPubAsst', 'pctUsePubTrans', 'pctKidsBornNevrMarr', 'pctOccupManu', 'pctUnemploy', 'pctWorkMom-18', 'pctFgnImmig-10', 'pctNotSpeakEng', 'pctPersOwnOccup', 'medRentpctHousInc', 'medGrossRent', 'pct12-21', 'pctLowEdu', 'pctCollGrad', 'pctHousOwnerOccup', 'pctMaleNevMar', 'pct12-29', 'perHoush', 'pctWdiv', 'pctWwage', 'persEmergShelt', 'pct65up', 'pctFgnImmig-8', 'pctLargHous', 'ownHousUperQ', 'pctNotHSgrad', 'ownHousMed', 'pctSpeakOnlyEng', 'pctFgnImmig-3', 'numForeignBorn', 'pctWsocsec', 'persPerOccupHous', 'medIncome', 'medFamIncome', 'rentMed', 'pctLargHousFam', 'pctImmig-8', 'pctFgnImmig-5', 'pctImmig-3', 'pctForeignBorn', 'pctImmig-10', 'persUrban', 'perCapInc', 'persPerFam', 'rentUpperQ', 'racialMatch', 'pctPolicHisp', 'pctImmig-5', 'nonViolPerPop']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def feature_selection(df, features_as_targets):\n",
    "    #drop the last 18 columns\n",
    "    if features_as_targets:\n",
    "        X = df.drop(df.columns[-1:], axis=1)\n",
    "    else:\n",
    "        X = df.drop(df.columns[-18:], axis=1)\n",
    "        \n",
    "    y = df['nonViolPerPop']\n",
    "    rf = RandomForestRegressor(n_estimators=100)\n",
    "    rf.fit(X, y)\n",
    "    importance = rf.feature_importances_\n",
    "    # print(np.sort(importance))\n",
    "    indices = np.argsort(importance)[::-1]\n",
    "    kept_cols = []\n",
    "    for f in range(X.shape[1]):\n",
    "        if importance[indices[f]] > 0.001:\n",
    "            kept_cols.append(X.columns[indices[f]])\n",
    "    #put nonViolPerPop back in\n",
    "    kept_cols.append('nonViolPerPop')\n",
    "    return df[kept_cols], kept_cols\n",
    "\n",
    "\n",
    "def fine_tune_features_approach(df, features_as_targets = False, do_normalize = False):\n",
    "    if do_normalize:\n",
    "        black_box_df = fill_with_mean(normalize(drop_rows_missing_target(convert_categorical_to_numeric(df))))\n",
    "    else: \n",
    "        black_box_df = fill_with_mean(drop_rows_missing_target(convert_categorical_to_numeric(df)))\n",
    "\n",
    "\n",
    "    black_box_df, kept_cols = feature_selection(black_box_df, features_as_targets)\n",
    "\n",
    "    train, test = train_test_split(black_box_df, test_size=0.2)\n",
    "\n",
    "    X_train = train.drop(train.columns[-1], axis=1)\n",
    "    y_train = train['nonViolPerPop']\n",
    "    X_test = test.drop(test.columns[-1], axis=1)\n",
    "    y_test = test['nonViolPerPop']\n",
    "\n",
    "    # Create the model with 100 trees\n",
    "    model = RandomForestRegressor(n_estimators=100,\n",
    "                                    bootstrap = True,\n",
    "                                    max_features = 'sqrt')\n",
    "    # Fit on training data\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Actual class predictions\n",
    "    rf_predictions = model.predict(X_test)\n",
    "\n",
    "    #calculate mae\n",
    "    mae = np.mean(abs(rf_predictions - y_test))\n",
    "    print('Mean Absolute Error:', mae)\n",
    "    print('Kept columns:', kept_cols)\n",
    "    print()\n",
    "    \n",
    "print('Using targets as features (normalize):')\n",
    "fine_tune_features_approach(df, True, True)\n",
    "print('\\n\\nNot using targets as features (normalize):')\n",
    "fine_tune_features_approach(df, False, True)\n",
    "print('\\n\\nUsing targets as features (no normalize):')\n",
    "fine_tune_features_approach(df, True, False)\n",
    "print('\\n\\nNot using targets as features (no normalize):')\n",
    "fine_tune_features_approach(df, False, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using targets as features (normalize):\n",
      "Mean Absolute Error: 0.22052116640642036\n",
      "\n",
      "\n",
      "Not using targets as features (normalize):\n",
      "Mean Absolute Error: 0.4794718581961971\n",
      "\n",
      "\n",
      "Using targets as features (no normalize):\n",
      "Mean Absolute Error: 646.535995754717\n",
      "\n",
      "\n",
      "Not using targets as features (no normalize):\n",
      "Mean Absolute Error: 1171.0694393867925\n"
     ]
    }
   ],
   "source": [
    "# https://www.geeksforgeeks.org/random-forest-regression-in-python/\n",
    "\n",
    "def random_forest_approach(df, features_as_targets = False, do_normalize = False):\n",
    "    for i in range(1):\n",
    "        black_box_df = df.copy()\n",
    "\n",
    "        if not features_as_targets:\n",
    "            black_box_df = black_box_df.drop(black_box_df.columns[-17:-1], axis=1)\n",
    "        if do_normalize:\n",
    "            black_box_df = fill_with_mean(normalize(drop_rows_missing_target(convert_categorical_to_numeric(black_box_df))))\n",
    "        else:\n",
    "            black_box_df = fill_with_mean(drop_rows_missing_target(convert_categorical_to_numeric(black_box_df)))\n",
    "\n",
    "\n",
    "        train, test = train_test_split(black_box_df, test_size=0.2)\n",
    "        X_train = train.drop(train.columns[-1], axis=1)\n",
    "        y_train = train['nonViolPerPop']\n",
    "        X_test = test.drop(test.columns[-1], axis=1)\n",
    "        y_test = test['nonViolPerPop']\n",
    "\n",
    "        # Create the model with 100 trees\n",
    "        model = RandomForestRegressor(n_estimators=100,\n",
    "                                        bootstrap = True,\n",
    "                                        max_features = 'sqrt')\n",
    "        # Fit on training data\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Actual class predictions\n",
    "        rf_predictions = model.predict(X_test)\n",
    "\n",
    "        #calculate mae\n",
    "        mae = np.mean(abs(rf_predictions - y_test))\n",
    "        print('Mean Absolute Error:', mae)\n",
    "\n",
    "        \n",
    "        \n",
    "print('Using targets as features (normalize):')\n",
    "random_forest_approach(df, True, True)\n",
    "print('\\n\\nNot using targets as features (normalize):')\n",
    "random_forest_approach(df, False, True)\n",
    "print('\\n\\nUsing targets as features (no normalize):')\n",
    "random_forest_approach(df, True, False)\n",
    "print('\\n\\nNot using targets as features (no normalize):')\n",
    "random_forest_approach(df, False, False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainable - Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using targets as features (normalized):\n",
      "alpha: 0.0011443488073478402\n",
      "Mean Absolute Error: 0.0011888445823240094\n",
      "kept Columns: ['larcPerPop: 0.69853', 'burglPerPop: 0.27936', 'autoTheftPerPop: 0.18384', 'arsonsPerPop: 0.01364']\n",
      "R squared: 0.9999977157988518\n",
      "\n",
      "\n",
      "Not using targets as features (normalized):\n",
      "alpha: 0.003747226429140997\n",
      "Mean Absolute Error: 0.45009916973494546\n",
      "kept Columns: ['pctForeignBorn: 0.27864', 'pctKids2Par: -0.27127', 'pctWsocsec: 0.20505', 'pctPoverty: 0.15096', 'popDensity: -0.13780', 'pctEmploy: 0.13577', 'pctLowEdu: -0.12349', 'pctMaleNevMar: 0.11704', 'pctMaleDivorc: 0.11179', 'pctRetire: -0.10782', 'pctImmig-8: -0.10683', 'pctFgnImmig-10: 0.09722', 'pctKidsBornNevrMarr: 0.09693', 'perHoush: -0.08886', 'pct12-29: -0.08309', 'pctLargHous: 0.08168', 'whitePerCap: 0.08090', 'medOwnCostpct: -0.08086', 'houseVacant: 0.07387', 'medYrHousBuilt: 0.06661', 'pctEmployMfg: -0.06495', 'pctSpeakOnlyEng: -0.06250', 'ownHousUperQ: -0.06214', 'pctSmallHousUnits: -0.06123', 'kidsBornNevrMarr: -0.06041', 'rentLowQ: -0.05977', 'rentUpperQ: -0.05762', 'pctVacant6up: -0.05719', 'pctFemDivorc: 0.05689', 'pctBornStateResid: -0.05450', 'pctOfficDrugUnit: 0.05376', 'pctImmig-3: -0.05195', 'pctPolicBlack: -0.04654', 'pctFgnImmig-5: -0.04444', 'pct12-17w2Par: -0.04001', 'otherPerCap: 0.03749', 'policeCalls: -0.03438', 'pctUrban: 0.03389', 'blackPerCap: -0.03339', 'pct2Par: -0.02678', 'asianPerCap: -0.02380', 'pctWorkMom-18: -0.02351', 'pctHousOccup: -0.02316', 'numDiffDrugsSeiz: -0.02205', 'pctSameCounty-5: 0.02146', 'persPerOccupHous: 0.01897', 'hispPerCap: 0.01641', 'pctWfarm: -0.01616', 'medNumBedrm: -0.01600', 'persPerOwnOccup: -0.01530', 'pctEmployProfServ: -0.01500', 'persEmergShelt: 0.01413', 'policAveOT: -0.01402', 'medOwnCostPctWO: -0.01361', 'pctPolicHisp: 0.01312', 'pctPersOwnOccup: -0.01307', 'pctHousWOphone: 0.01223', 'ownHousQrange: -0.01189', 'pctOccupMgmt: 0.01184', 'pct65up: 0.01108', 'medFamIncome: -0.01006', 'pctPolicAsian: 0.01001', 'landArea: -0.00826', 'pctCollGrad: -0.00642', 'policCallPerOffic: 0.00610', 'pctLargHousFam: 0.00526', 'pctPolicPatrol: 0.00498', 'pctNotSpeakEng: 0.00390', 'NAperCap: -0.00148', 'State: -0.00103']\n",
      "R squared: 0.5365852168300083\n",
      "\n",
      "\n",
      "Using targets as features (not normalized):\n",
      "alpha: 2556870.3340053125\n",
      "Mean Absolute Error: 1124.677624590721\n",
      "kept Columns: ['larcPerPop: 0.47547', 'medFamIncome: -0.03638', 'medIncome: -0.01569', 'persUrban: 0.00602', 'numForeignBorn: -0.00292', 'policCallPerPop: 0.00284', 'ownHousQrange: 0.00177', 'policeCalls: -0.00135', 'policOperBudget: -0.00001']\n",
      "R squared: 0.6523623599468857\n",
      "\n",
      "\n",
      "Not using targets as features (not normalized):\n",
      "alpha: 2556870.3340053125\n",
      "Mean Absolute Error: 1696.8626325385528\n",
      "kept Columns: ['medIncome: -0.05144', 'medFamIncome: -0.02962', 'persUrban: 0.00811', 'numForeignBorn: -0.00507', 'policCallPerPop: 0.00297', 'ownHousQrange: 0.00281', 'policeCalls: -0.00191', 'ownHousUperQ: 0.00038', 'policOperBudget: -0.00002']\n",
      "R squared: 0.2849665362929785\n"
     ]
    }
   ],
   "source": [
    "#doing lasso \n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "def lasso(df, features_as_targets, do_normalize):\n",
    "    if do_normalize:\n",
    "        lasso_df = fill_with_mean(normalize(drop_rows_missing_target(convert_categorical_to_numeric(df))))\n",
    "    else:\n",
    "        lasso_df = fill_with_mean(drop_rows_missing_target(convert_categorical_to_numeric(df)))\n",
    "\n",
    "\n",
    "\n",
    "    if features_as_targets:\n",
    "        X = lasso_df.drop(lasso_df.columns[-1:], axis=1)\n",
    "    else:\n",
    "        X = lasso_df.drop(lasso_df.columns[-18:], axis=1)\n",
    "    y = lasso_df['nonViolPerPop']\n",
    "\n",
    "    alpha_predict = LassoCV(cv=5, random_state=0, max_iter=10000)\n",
    "    alpha_predict.fit(X, y)\n",
    "    print(\"alpha: \" + str(alpha_predict.alpha_))\n",
    "    model = Lasso(alpha=alpha_predict.alpha_)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = np.mean(abs(y_pred - y_test))\n",
    "    print('Mean Absolute Error:', mae)\n",
    "    coef_dict = { k:v for (k,v) in zip(model.coef_, X)}\n",
    "    #sort coef_dict by abs value\n",
    "    coef_dict = {k: v for k, v in sorted(coef_dict.items(), key=lambda item: abs(item[0]), reverse=True)}\n",
    "\n",
    "    print('kept Columns:', [f'{v}: {k:.5f}' for k,v in coef_dict.items() if k > 0.00001 or k < -0.00001])\n",
    "    #print R squared\n",
    "    print('R squared:', model.score(X_test, y_test))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Using targets as features (normalized):')\n",
    "lasso(df, True, True)\n",
    "print('\\n\\nNot using targets as features (normalized):')\n",
    "lasso(df, False, True)\n",
    "print('\\n\\nUsing targets as features (not normalized):')\n",
    "lasso(df, True, False)\n",
    "print('\\n\\nNot using targets as features (not normalized):')\n",
    "lasso(df, False, False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
