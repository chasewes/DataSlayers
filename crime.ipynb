{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the crime thing Dr. Paige asked us to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import shutup; shutup.please()\n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.io import arff\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>pop</th>\n",
       "      <th>perHoush</th>\n",
       "      <th>pctBlack</th>\n",
       "      <th>pctWhite</th>\n",
       "      <th>pctAsian</th>\n",
       "      <th>pctHisp</th>\n",
       "      <th>pct12-21</th>\n",
       "      <th>pct12-29</th>\n",
       "      <th>pct16-24</th>\n",
       "      <th>...</th>\n",
       "      <th>burglaries</th>\n",
       "      <th>burglPerPop</th>\n",
       "      <th>larcenies</th>\n",
       "      <th>larcPerPop</th>\n",
       "      <th>autoTheft</th>\n",
       "      <th>autoTheftPerPop</th>\n",
       "      <th>arsons</th>\n",
       "      <th>arsonsPerPop</th>\n",
       "      <th>violentPerPop</th>\n",
       "      <th>nonViolPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NJ</td>\n",
       "      <td>11980.0</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.37</td>\n",
       "      <td>91.78</td>\n",
       "      <td>6.50</td>\n",
       "      <td>1.88</td>\n",
       "      <td>12.47</td>\n",
       "      <td>21.44</td>\n",
       "      <td>10.93</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>114.85</td>\n",
       "      <td>138.0</td>\n",
       "      <td>1132.08</td>\n",
       "      <td>16.0</td>\n",
       "      <td>131.26</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.41</td>\n",
       "      <td>41.02</td>\n",
       "      <td>1394.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PA</td>\n",
       "      <td>23123.0</td>\n",
       "      <td>2.82</td>\n",
       "      <td>0.80</td>\n",
       "      <td>95.57</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0.85</td>\n",
       "      <td>11.01</td>\n",
       "      <td>21.30</td>\n",
       "      <td>10.48</td>\n",
       "      <td>...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>242.37</td>\n",
       "      <td>376.0</td>\n",
       "      <td>1598.78</td>\n",
       "      <td>26.0</td>\n",
       "      <td>110.55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.25</td>\n",
       "      <td>127.56</td>\n",
       "      <td>1955.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OR</td>\n",
       "      <td>29344.0</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.74</td>\n",
       "      <td>94.33</td>\n",
       "      <td>3.43</td>\n",
       "      <td>2.35</td>\n",
       "      <td>11.36</td>\n",
       "      <td>25.88</td>\n",
       "      <td>11.01</td>\n",
       "      <td>...</td>\n",
       "      <td>274.0</td>\n",
       "      <td>758.14</td>\n",
       "      <td>1797.0</td>\n",
       "      <td>4972.19</td>\n",
       "      <td>136.0</td>\n",
       "      <td>376.30</td>\n",
       "      <td>22.0</td>\n",
       "      <td>60.87</td>\n",
       "      <td>218.59</td>\n",
       "      <td>6167.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NY</td>\n",
       "      <td>16656.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.70</td>\n",
       "      <td>97.35</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.70</td>\n",
       "      <td>12.55</td>\n",
       "      <td>25.20</td>\n",
       "      <td>12.19</td>\n",
       "      <td>...</td>\n",
       "      <td>225.0</td>\n",
       "      <td>1301.78</td>\n",
       "      <td>716.0</td>\n",
       "      <td>4142.56</td>\n",
       "      <td>47.0</td>\n",
       "      <td>271.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>306.64</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MN</td>\n",
       "      <td>11245.0</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.53</td>\n",
       "      <td>89.16</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.52</td>\n",
       "      <td>24.46</td>\n",
       "      <td>40.53</td>\n",
       "      <td>28.69</td>\n",
       "      <td>...</td>\n",
       "      <td>91.0</td>\n",
       "      <td>728.93</td>\n",
       "      <td>1060.0</td>\n",
       "      <td>8490.87</td>\n",
       "      <td>91.0</td>\n",
       "      <td>728.93</td>\n",
       "      <td>5.0</td>\n",
       "      <td>40.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9988.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 143 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  State      pop  perHoush  pctBlack  pctWhite  pctAsian  pctHisp  pct12-21  \\\n",
       "0    NJ  11980.0      3.10      1.37     91.78      6.50     1.88     12.47   \n",
       "1    PA  23123.0      2.82      0.80     95.57      3.44     0.85     11.01   \n",
       "2    OR  29344.0      2.43      0.74     94.33      3.43     2.35     11.36   \n",
       "3    NY  16656.0      2.40      1.70     97.35      0.50     0.70     12.55   \n",
       "4    MN  11245.0      2.76      0.53     89.16      1.17     0.52     24.46   \n",
       "\n",
       "   pct12-29  pct16-24  ...  burglaries  burglPerPop  larcenies  larcPerPop  \\\n",
       "0     21.44     10.93  ...        14.0       114.85      138.0     1132.08   \n",
       "1     21.30     10.48  ...        57.0       242.37      376.0     1598.78   \n",
       "2     25.88     11.01  ...       274.0       758.14     1797.0     4972.19   \n",
       "3     25.20     12.19  ...       225.0      1301.78      716.0     4142.56   \n",
       "4     40.53     28.69  ...        91.0       728.93     1060.0     8490.87   \n",
       "\n",
       "   autoTheft  autoTheftPerPop  arsons  arsonsPerPop  violentPerPop  \\\n",
       "0       16.0           131.26     2.0         16.41          41.02   \n",
       "1       26.0           110.55     1.0          4.25         127.56   \n",
       "2      136.0           376.30    22.0         60.87         218.59   \n",
       "3       47.0           271.93     NaN           NaN         306.64   \n",
       "4       91.0           728.93     5.0         40.05            NaN   \n",
       "\n",
       "   nonViolPerPop  \n",
       "0        1394.59  \n",
       "1        1955.95  \n",
       "2        6167.51  \n",
       "3            NaN  \n",
       "4        9988.79  \n",
       "\n",
       "[5 rows x 143 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data\n",
    "\n",
    "df = pd.read_csv('data/CommViolPredUnnormalizedData.txt', encoding='latin-1',header=None)\n",
    "df.columns\n",
    "#the column names are the second word in each row of data/crime_headings.txt\n",
    "with open('data/crime_headings.txt') as f:\n",
    "    headings = f.readlines()\n",
    "col_names = []\n",
    "types = []\n",
    "for heading in headings:\n",
    "    if len(heading.split()) <= 1:\n",
    "        continue\n",
    "    col_names.append(heading.split()[1])\n",
    "    if heading.split()[2] == 'numeric':\n",
    "        types.append(float)\n",
    "    else:\n",
    "        types.append(str)\n",
    "\n",
    "df.columns = col_names\n",
    "\n",
    "#drop drop rows with \"?\" values\n",
    "df = df.replace('?', np.nan)\n",
    "\n",
    "df = df.astype(dict(zip(col_names, types)))\n",
    "\n",
    "#communityname, countyCode, communityCode, fold are not predictive so drop them\n",
    "df = df.drop(['communityname', 'countyCode', 'communityCode', 'fold'], axis=1)\n",
    "df.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#useful functions\n",
    "def drop_rows_missing_target(df):\n",
    "    return df.dropna(subset=['nonViolPerPop'])\n",
    "\n",
    "\n",
    "def fill_with_mean(df):\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == float:\n",
    "            df[column] = df[column].fillna(df[column].mean())\n",
    "    return df\n",
    "\n",
    "def fill_with_median(df):\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == float:\n",
    "            df[column] = df[column].fillna(df[column].median())\n",
    "    return df\n",
    "\n",
    "def convert_categorical_to_numeric(df):\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype != float:\n",
    "            df[column] = df[column].astype('category')\n",
    "            df[column] = df[column].cat.codes\n",
    "    return df\n",
    "\n",
    "def normalize(df):\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == float:\n",
    "            df[column] = (df[column] - df[column].mean()) / df[column].std()\n",
    "    return df\n",
    "\n",
    "def remove_random_features(df, n):\n",
    "    dropped_cols = np.random.choice(df.columns[:-1], n, replace=False)\n",
    "    return df.drop(dropped_cols, axis=1), dropped_cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to remove the missing values of the dataset as effectively as possible. We first dropped the columns with more that 80% missing values. Then after dropping the columns with more than 80% \n",
    "missing values, we then dropped all rows that also have a missing value in our target nonViolPerPop. After that we filled the remaining missing values in the columns with the mean value of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2215, 143)\n",
      "(2215, 121)\n",
      "(2118, 121)\n",
      "(2118, 121)\n",
      "Empty DataFrame\n",
      "Columns: [State, pop, perHoush, pctBlack, pctWhite, pctAsian, pctHisp, pct12-21, pct12-29, pct16-24, pct65up, persUrban, pctUrban, medIncome, pctWwage, pctWfarm, pctWdiv, pctWsocsec, pctPubAsst, pctRetire, medFamIncome, perCapInc, whitePerCap, blackPerCap, NAperCap, asianPerCap, otherPerCap, hispPerCap, persPoverty, pctPoverty, pctLowEdu, pctNotHSgrad, pctCollGrad, pctUnemploy, pctEmploy, pctEmployMfg, pctEmployProfServ, pctOccupManu, pctOccupMgmt, pctMaleDivorc, pctMaleNevMar, pctFemDivorc, pctAllDivorc, persPerFam, pct2Par, pctKids2Par, pctKids-4w2Par, pct12-17w2Par, pctWorkMom-6, pctWorkMom-18, kidsBornNevrMarr, pctKidsBornNevrMarr, numForeignBorn, pctFgnImmig-3, pctFgnImmig-5, pctFgnImmig-8, pctFgnImmig-10, pctImmig-3, pctImmig-5, pctImmig-8, pctImmig-10, pctSpeakOnlyEng, pctNotSpeakEng, pctLargHousFam, pctLargHous, persPerOccupHous, persPerOwnOccup, persPerRenterOccup, pctPersOwnOccup, pctPopDenseHous, pctSmallHousUnits, medNumBedrm, houseVacant, pctHousOccup, pctHousOwnerOccup, pctVacantBoarded, pctVacant6up, medYrHousBuilt, pctHousWOphone, pctHousWOplumb, ownHousLowQ, ownHousMed, ownHousUperQ, ownHousQrange, rentLowQ, rentMed, rentUpperQ, rentQrange, medGrossRent, medRentpctHousInc, medOwnCostpct, medOwnCostPctWO, persEmergShelt, persHomeless, pctForeignBorn, pctBornStateResid, pctSameHouse-5, pctSameCounty-5, pctSameState-5, landArea, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 121 columns]\n",
      "0       1394.59\n",
      "1       1955.95\n",
      "2       6167.51\n",
      "4       9988.79\n",
      "5       6867.42\n",
      "         ...   \n",
      "2210    7356.84\n",
      "2211    5824.44\n",
      "2212    4654.20\n",
      "2213    5340.87\n",
      "2214    8838.50\n",
      "Name: nonViolPerPop, Length: 2118, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# function to drop the columnns with more that 80% missing values\n",
    "print(df.shape)\n",
    "def drop_missing_values(df):\n",
    "    for column in df.columns:\n",
    "        if df[column].isnull().sum() > 0.8*len(df):\n",
    "            df = df.drop(column, axis=1)\n",
    "    return df\n",
    "# drop the columns with more than 80% missing values\n",
    "df = drop_missing_values(df)\n",
    "print(df.shape)\n",
    "# drop the rows with missing values from the nonViolPerPop column\n",
    "df = drop_rows_missing_target(df)\n",
    "print(df.shape)\n",
    "#fill the missing values with the mean\n",
    "df_mean = fill_with_mean(df)\n",
    "#fill the missing values with the median\n",
    "df_median = fill_with_median(df)\n",
    "# print rows with still containing np.nan values\n",
    "df = df_mean\n",
    "print(df.shape)\n",
    "print(df[df.isnull().any(axis=1)])\n",
    "# print the target column\n",
    "print(df['nonViolPerPop'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pseudo-Explainable Approach - Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using targets as features:\n",
      "Mean Absolute Error: 0.05829831319538622\n",
      "Kept columns: ['larcPerPop', 'burglPerPop', 'autoTheftPerPop', 'nonViolPerPop']\n",
      "\n",
      "\n",
      "\n",
      "Not using targets as features:\n",
      "Mean Absolute Error: 0.44887761090677913\n",
      "Kept columns: ['pctKids2Par', 'pct2Par', 'rentLowQ', 'pctAllDivorc', 'pct12-17w2Par', 'pctMaleDivorc', 'persHomeless', 'pctHousOccup', 'houseVacant', 'pctPopDenseHous', 'pctFemDivorc', 'kidsBornNevrMarr', 'persPoverty', 'nonViolPerPop']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def feature_selection(df, features_as_targets):\n",
    "    #drop the last 18 columns\n",
    "    if features_as_targets:\n",
    "        X = df.drop(df.columns[-1:], axis=1)\n",
    "    else:\n",
    "        X = df.drop(df.columns[-18:], axis=1)\n",
    "        \n",
    "    y = df['nonViolPerPop']\n",
    "    rf = RandomForestRegressor(n_estimators=100)\n",
    "    rf.fit(X, y)\n",
    "    importance = rf.feature_importances_\n",
    "    # print(np.sort(importance))\n",
    "    indices = np.argsort(importance)[::-1]\n",
    "    kept_cols = []\n",
    "    for f in range(X.shape[1]):\n",
    "        if importance[indices[f]] > 0.01:\n",
    "            kept_cols.append(X.columns[indices[f]])\n",
    "    #put nonViolPerPop back in\n",
    "    kept_cols.append('nonViolPerPop')\n",
    "    return df[kept_cols], kept_cols\n",
    "\n",
    "\n",
    "def fine_tune_features_approach(df, features_as_targets = False):\n",
    "    black_box_df = fill_with_mean(normalize(drop_rows_missing_target(convert_categorical_to_numeric(df))))\n",
    "\n",
    "    black_box_df, kept_cols = feature_selection(black_box_df, features_as_targets)\n",
    "\n",
    "    train, test = train_test_split(black_box_df, test_size=0.2)\n",
    "\n",
    "    X_train = train.drop(train.columns[-1], axis=1)\n",
    "    y_train = train['nonViolPerPop']\n",
    "    X_test = test.drop(test.columns[-1], axis=1)\n",
    "    y_test = test['nonViolPerPop']\n",
    "\n",
    "    # Create the model with 100 trees\n",
    "    model = RandomForestRegressor(n_estimators=100,\n",
    "                                    bootstrap = True,\n",
    "                                    max_features = 'sqrt')\n",
    "    # Fit on training data\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Actual class predictions\n",
    "    rf_predictions = model.predict(X_test)\n",
    "\n",
    "    #calculate mae\n",
    "    mae = np.mean(abs(rf_predictions - y_test))\n",
    "    print('Mean Absolute Error:', mae)\n",
    "    print('Kept columns:', kept_cols)\n",
    "    print()\n",
    "print('Using targets as features:')\n",
    "fine_tune_features_approach(df, True)\n",
    "print('\\n\\nNot using targets as features:')\n",
    "fine_tune_features_approach(df, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using targets as features (normalize):\n",
      "Mean Absolute Error: 0.19194033910799055\n",
      "\n",
      "\n",
      "Not using targets as features (normalize):\n",
      "Mean Absolute Error: 0.4552270940981703\n",
      "\n",
      "\n",
      "Using targets as features (no normalize):\n",
      "Mean Absolute Error: 560.7038662735849\n",
      "\n",
      "\n",
      "Not using targets as features (no normalize):\n",
      "Mean Absolute Error: 1238.4515365566042\n"
     ]
    }
   ],
   "source": [
    "# https://www.geeksforgeeks.org/random-forest-regression-in-python/\n",
    "\n",
    "def random_forest_approach(df, features_as_targets = False, do_normalize = False):\n",
    "    for i in range(1):\n",
    "        black_box_df = df.copy()\n",
    "\n",
    "        if not features_as_targets:\n",
    "            black_box_df = black_box_df.drop(black_box_df.columns[-17:-1], axis=1)\n",
    "        if do_normalize:\n",
    "            black_box_df = fill_with_mean(normalize(drop_rows_missing_target(convert_categorical_to_numeric(black_box_df))))\n",
    "        else:\n",
    "            black_box_df = fill_with_mean(drop_rows_missing_target(convert_categorical_to_numeric(black_box_df)))\n",
    "\n",
    "\n",
    "        train, test = train_test_split(black_box_df, test_size=0.2)\n",
    "        X_train = train.drop(train.columns[-1], axis=1)\n",
    "        y_train = train['nonViolPerPop']\n",
    "        X_test = test.drop(test.columns[-1], axis=1)\n",
    "        y_test = test['nonViolPerPop']\n",
    "\n",
    "        # Create the model with 100 trees\n",
    "        model = RandomForestRegressor(n_estimators=100,\n",
    "                                        bootstrap = True,\n",
    "                                        max_features = 'sqrt')\n",
    "        # Fit on training data\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Actual class predictions\n",
    "        rf_predictions = model.predict(X_test)\n",
    "\n",
    "        #calculate mae\n",
    "        mae = np.mean(abs(rf_predictions - y_test))\n",
    "        print('Mean Absolute Error:', mae)\n",
    "\n",
    "        \n",
    "        \n",
    "print('Using targets as features (normalize):')\n",
    "random_forest_approach(df, True, True)\n",
    "print('\\n\\nNot using targets as features (normalize):')\n",
    "random_forest_approach(df, False, True)\n",
    "print('\\n\\nUsing targets as features (no normalize):')\n",
    "random_forest_approach(df, True, False)\n",
    "print('\\n\\nNot using targets as features (no normalize):')\n",
    "random_forest_approach(df, False, False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainable - Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using targets as features (normalized):\n",
      "Mean Absolute Error: 0.001005574687510722\n",
      "kept Columns: ['larcPerPop: 0.69857', 'burglPerPop: 0.27940', 'autoTheftPerPop: 0.18390', 'arsonsPerPop: 0.01368', 'robbbPerPop: 0.00004']\n",
      "R squared: 0.9999982030468577\n",
      "\n",
      "\n",
      "Not using targets as features (normalized):\n",
      "Mean Absolute Error: 0.4774601287576555\n",
      "kept Columns: ['pctMaleNevMar: 0.30015', 'pctWsocsec: 0.28860', 'pctForeignBorn: 0.27083', 'pctPoverty: 0.19908', 'pctEmploy: 0.19451', 'pctMaleDivorc: 0.17537', 'persPerOccupHous: 0.17529', 'whitePerCap: 0.15515', 'perHoush: -0.15210', 'pct16-24: -0.14875', 'pctLowEdu: -0.14708', 'popDensity: -0.13623', 'houseVacant: 0.13296', 'kidsBornNevrMarr: -0.11724', 'rentLowQ: -0.11564', 'pctKids2Par: -0.11521', 'pctCollGrad: -0.10563', 'pctRetire: -0.10350', 'pctImmig-3: -0.10036', 'pctFgnImmig-10: 0.09913', 'ownHousUperQ: -0.09001', 'pctFemDivorc: 0.08750', 'medOwnCostpct: -0.08701', 'pctImmig-8: -0.08239', 'pct12-21: 0.08226', 'pct12-29: -0.07941', 'pctKidsBornNevrMarr: 0.07873', 'pctFgnImmig-5: -0.07776', 'pctSmallHousUnits: -0.07500', 'pct2Par: -0.07112', 'pctEmployMfg: -0.06806', 'pctSpeakOnlyEng: -0.06698', 'pctBornStateResid: -0.06672', 'medYrHousBuilt: 0.06515', 'pctOccupMgmt: 0.06343', 'persPerOwnOccup: -0.05884', 'pct12-17w2Par: -0.05611', 'pctVacant6up: -0.05156', 'medFamIncome: -0.05116', 'persEmergShelt: 0.05114', 'pctOfficDrugUnit: 0.04440', 'pctWwage: 0.04152', 'pctWdiv: 0.04139', 'pctFgnImmig-8: 0.04101', 'otherPerCap: 0.03946', 'pctUrban: 0.03944', 'landArea: -0.03808', 'pctLargHous: 0.03671', 'persUrban: -0.03558', 'rentUpperQ: -0.03305', 'pctWorkMom-18: -0.03242', 'pctNotSpeakEng: 0.03175', 'pctHousWOphone: 0.03120', 'medNumBedrm: -0.02832', 'pctEmployProfServ: -0.02702', 'pctUnemploy: -0.02658', 'pctPopDenseHous: 0.02378', 'pct65up: 0.02297', 'NAperCap: -0.02251', 'pctVacantBoarded: -0.02228', 'pctWorkMom-6: -0.02012', 'pctHousOccup: -0.01929', 'pctPubAsst: -0.01858', 'pctWhite: -0.01791', 'blackPerCap: -0.01760', 'ownHousQrange: -0.01754', 'pctBlack: 0.01438', 'asianPerCap: -0.01317', 'persPerRenterOccup: -0.00997', 'pctFgnImmig-3: 0.00683', 'pctSameHouse-5: -0.00600', 'medOwnCostPctWO: -0.00496', 'pctNotHSgrad: -0.00486', 'pctUsePubTrans: -0.00468', 'pctWfarm: -0.00386', 'pctPersOwnOccup: -0.00111', 'State: -0.00051']\n",
      "R squared: 0.5642883642978838\n",
      "\n",
      "\n",
      "Using targets as features (not normalized):\n",
      "Mean Absolute Error: 112.17094146234952\n",
      "kept Columns: ['larcPerPop: 1.02122', 'burglPerPop: 0.92453', 'autoTheftPerPop: 0.68126', 'medFamIncome: -0.00759', 'popDensity: 0.00746', 'numForeignBorn: -0.00164', 'persUrban: 0.00162', 'pop: -0.00105', 'ownHousUperQ: 0.00057', 'ownHousMed: 0.00036']\n",
      "R squared: 0.9967044653951569\n",
      "\n",
      "\n",
      "Not using targets as features (not normalized):\n",
      "Mean Absolute Error: 1530.2626012124\n",
      "kept Columns: ['whitePerCap: 0.62866', 'perCapInc: -0.35288', 'medFamIncome: -0.19733', 'kidsBornNevrMarr: -0.03399', 'otherPerCap: 0.02090', 'persUrban: 0.01706', 'ownHousMed: 0.01440', 'asianPerCap: -0.01259', 'pop: -0.01215', 'numForeignBorn: -0.00982', 'ownHousLowQ: -0.00765', 'houseVacant: -0.00633', 'ownHousUperQ: -0.00588', 'hispPerCap: -0.00156', 'NAperCap: 0.00151', 'persPoverty: 0.00066']\n",
      "R squared: 0.3254745750491933\n"
     ]
    }
   ],
   "source": [
    "#doing lasso \n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "def lasso(df, features_as_targets, do_normalize):\n",
    "    if do_normalize:\n",
    "        lasso_df = fill_with_mean(normalize(drop_rows_missing_target(convert_categorical_to_numeric(df))))\n",
    "    else:\n",
    "        lasso_df = fill_with_mean(drop_rows_missing_target(convert_categorical_to_numeric(df)))\n",
    "\n",
    "\n",
    "\n",
    "    if features_as_targets:\n",
    "        X = lasso_df.drop(lasso_df.columns[-1:], axis=1)\n",
    "    else:\n",
    "        X = lasso_df.drop(lasso_df.columns[-18:], axis=1)\n",
    "    y = lasso_df['nonViolPerPop']\n",
    "\n",
    "    alpha_predict = LassoCV(cv=5, random_state=0, max_iter=10000)\n",
    "    alpha_predict.fit(X, y)\n",
    "\n",
    "    model = Lasso(alpha=alpha_predict.alpha_)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = np.mean(abs(y_pred - y_test))\n",
    "    print('Mean Absolute Error:', mae)\n",
    "    coef_dict = { k:v for (k,v) in zip(model.coef_, X)}\n",
    "    #sort coef_dict by abs value\n",
    "    coef_dict = {k: v for k, v in sorted(coef_dict.items(), key=lambda item: abs(item[0]), reverse=True)}\n",
    "\n",
    "    print('kept Columns:', [f'{v}: {k:.5f}' for k,v in coef_dict.items() if k > 0.00001 or k < -0.00001])\n",
    "    #print R squared\n",
    "    print('R squared:', model.score(X_test, y_test))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Using targets as features (normalized):')\n",
    "lasso(df, True, True)\n",
    "print('\\n\\nNot using targets as features (normalized):')\n",
    "lasso(df, False, True)\n",
    "print('\\n\\nUsing targets as features (not normalized):')\n",
    "lasso(df, True, False)\n",
    "print('\\n\\nNot using targets as features (not normalized):')\n",
    "lasso(df, False, False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
